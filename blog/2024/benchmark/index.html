<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Common Tools in Reinforcement Learning for Benchmarking | Hemant Kumawat </title> <meta name="author" content="Hemant Kumawat"> <meta name="description" content="A guide to the most popular tools used in reinforcement learning for benchmarking algorithms."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/profile.png?df1aaaac10cbbc5bca572b1a60d2d5e7"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kumawathemant.github.io/blog/2024/benchmark/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Hemant</span> Kumawat </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">Research </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Common Tools in Reinforcement Learning for Benchmarking</h1> <p class="post-meta"> Created in April 20, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/ml"> <i class="fa-solid fa-hashtag fa-sm"></i> ml</a>   <a href="/blog/tag/rl"> <i class="fa-solid fa-hashtag fa-sm"></i> rl</a>   <a href="/blog/tag/mujoco"> <i class="fa-solid fa-hashtag fa-sm"></i> mujoco</a>   <a href="/blog/tag/benchmarking"> <i class="fa-solid fa-hashtag fa-sm"></i> benchmarking</a>   ·   <a href="/blog/category/ai"> <i class="fa-solid fa-tag fa-sm"></i> AI</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Reinforcement Learning (RL) has gained tremendous traction in recent years, achieving remarkable success in various domains such as robotics, gaming, and autonomous driving. A key aspect of advancing RL research is the ability to benchmark algorithms effectively. To make this possible, researchers use a variety of standardized environments, libraries, and tools that allow for fair comparisons and consistent evaluation of different RL strategies. This blog will introduce some of the most common tools in RL for benchmarking.</p> <hr> <h2 id="1-openai-gym">1. OpenAI Gym</h2> <p><strong>What it is</strong>: OpenAI Gym is arguably the most widely used RL environment library. It provides a standardized API for RL environments, allowing researchers to test and compare algorithms with minimal changes to their code.</p> <p><strong>Key Features</strong>:</p> <ul> <li> <strong>Wide Range of Environments</strong>: Includes simple environments like the classic CartPole and MountainCar to complex environments like Atari games and robotics simulations.</li> <li> <strong>Simple Interface</strong>: Provides a consistent interface for environments, making it easy to create, reset, and interact with them.</li> <li> <strong>Community Support</strong>: Extensive community contributions lead to the creation of custom environments.</li> </ul> <p><strong>Use Case</strong>: Researchers often use Gym to test new RL algorithms, especially in the domain of discrete action spaces. Atari environments, in particular, have become a standard benchmark for deep RL research.</p> <hr> <h2 id="2-deepmind-control-suite">2. DeepMind Control Suite</h2> <p><strong>What it is</strong>: DeepMind’s Control Suite is a collection of standardized benchmark environments for continuous control tasks. It emphasizes high-quality simulation and evaluation consistency, specifically targeting continuous control domains like robotics.</p> <p><strong>Key Features</strong>:</p> <ul> <li> <strong>Realistic Physics Simulations</strong>: Provides a higher fidelity simulation compared to simpler environments, focusing on physics-based control tasks.</li> <li> <strong>High Consistency</strong>: Offers a set of environments with minimal variability, which helps in understanding the performance of RL algorithms on continuous control.</li> <li> <strong>Standardized Metrics</strong>: Provides clear and consistent metrics for evaluation.</li> </ul> <p><strong>Use Case</strong>: Ideal for evaluating algorithms designed for robotics and other physical systems where smooth and continuous control is crucial.</p> <hr> <h2 id="3-atari-learning-environment-ale">3. Atari Learning Environment (ALE)</h2> <p><strong>What it is</strong>: The Atari Learning Environment is a platform specifically designed for benchmarking RL algorithms using Atari 2600 games. It is widely used in the research community for evaluating general RL algorithms in discrete action spaces.</p> <p><strong>Key Features</strong>:</p> <ul> <li> <strong>Challenging Tasks</strong>: Atari games are considered challenging due to their high-dimensional observation space (raw pixels) and delayed rewards.</li> <li> <strong>Consistency</strong>: Provides a consistent and controlled testing environment.</li> <li> <strong>Variety</strong>: Offers over 50 different games, each with unique challenges.</li> </ul> <p><strong>Use Case</strong>: A go-to benchmark for deep reinforcement learning, particularly for algorithms dealing with high-dimensional inputs like raw pixel data.</p> <hr> <h2 id="4-mujoco-multi-joint-dynamics-with-contact">4. MuJoCo (Multi-Joint dynamics with Contact)</h2> <p><strong>What it is</strong>: MuJoCo is a physics engine known for its high-precision simulations. It is popular in continuous control tasks, such as simulating robotic arm movements or walking.</p> <p><strong>Key Features</strong>:</p> <ul> <li> <strong>Accurate Physics Simulation</strong>: Known for its accurate and stable simulations of dynamic systems, including multi-joint and contact-rich environments.</li> <li> <strong>Speed</strong>: Extremely fast simulation times compared to many other physics engines.</li> <li> <strong>Robustness</strong>: Handles complex interactions with various constraints and contacts efficiently.</li> </ul> <p><strong>Use Case</strong>: Frequently used in robotics research and other domains requiring precise physical simulations. It is often combined with OpenAI Gym’s interface for seamless integration.</p> <hr> <h2 id="5-pybullet">5. PyBullet</h2> <p><strong>What it is</strong>: PyBullet is an open-source physics simulation library, similar to MuJoCo but free to use. It’s a great alternative for continuous control tasks, particularly in robotics.</p> <p><strong>Key Features</strong>:</p> <ul> <li> <strong>Free and Open-Source</strong>: Provides a cost-effective alternative to proprietary tools like MuJoCo.</li> <li> <strong>Real-Time Simulation</strong>: Capable of running simulations in real-time.</li> <li> <strong>Versatility</strong>: Used for robotics, deep learning, and visual simulation tasks.</li> </ul> <p><strong>Use Case</strong>: A popular choice for prototyping and testing RL algorithms in robotics, especially in research settings where budget constraints are a consideration.</p> <hr> <h2 id="6-rllib-ray">6. RLlib (Ray)</h2> <p><strong>What it is</strong>: RLlib is a scalable reinforcement learning library built on top of Ray, a distributed computing framework. It provides a unified API for various RL algorithms, from simple to complex.</p> <p><strong>Key Features</strong>:</p> <ul> <li> <strong>Scalability</strong>: Easily run experiments on multiple cores or across a cluster.</li> <li> <strong>Pre-built Algorithms</strong>: Comes with a variety of pre-built RL algorithms like DQN, PPO, A3C, and SAC.</li> <li> <strong>Integration</strong>: Easily integrates with OpenAI Gym and other RL environments.</li> </ul> <p><strong>Use Case</strong>: Ideal for researchers who need to scale their experiments or run hyperparameter tuning across multiple machines.</p> <hr> <h2 id="7-dopamine">7. Dopamine</h2> <p><strong>What it is</strong>: Dopamine is a lightweight, easy-to-understand research framework for fast prototyping of RL algorithms. Developed by Google Research, it focuses on simplicity and replicability of experiments.</p> <p><strong>Key Features</strong>:</p> <ul> <li> <strong>Simple Implementation</strong>: Designed with clarity in mind, making it easy for newcomers to get started.</li> <li> <strong>Reproducibility</strong>: Emphasis on reproducible results, with baseline implementations of classic algorithms.</li> <li> <strong>Focus on Best Practices</strong>: Encourages best practices in RL research, such as proper evaluation and benchmarking.</li> </ul> <p><strong>Use Case</strong>: A great starting point for researchers who want to understand and prototype RL algorithms quickly without getting bogged down by complex setup requirements.</p> <hr> <h2 id="8-unity-ml-agents">8. Unity ML-Agents</h2> <p><strong>What it is</strong>: Unity ML-Agents is a toolkit for creating and training RL agents in Unity, a popular game development platform. It enables training in highly customizable and complex environments.</p> <p><strong>Key Features</strong>:</p> <ul> <li> <strong>Game-Like Environments</strong>: Provides visually rich and interactive environments for RL.</li> <li> <strong>Flexibility</strong>: Offers a high degree of customization, allowing researchers to design their own environments with ease.</li> <li> <strong>Multimodal Inputs</strong>: Supports diverse inputs like images, 3D coordinates, and more.</li> </ul> <p><strong>Use Case</strong>: Often used to explore complex behaviors, train agents in 3D environments, and perform experiments in domains like autonomous navigation and multi-agent interactions.</p> <hr> <h2 id="9-pettingzoo">9. PettingZoo</h2> <p><strong>What it is</strong>: PettingZoo is a library for multi-agent RL environments, developed by the same team behind Gym. It standardizes environments for multi-agent research, similar to how Gym standardizes single-agent environments.</p> <p><strong>Key Features</strong>:</p> <ul> <li> <strong>Multi-Agent Scenarios</strong>: Focuses on environments where multiple agents interact, collaborate, or compete.</li> <li> <strong>Standard API</strong>: Provides a Gym-like API, making it easier to switch between single-agent and multi-agent settings.</li> <li> <strong>Diverse Environments</strong>: Offers a variety of environments, from cooperative to competitive scenarios.</li> </ul> <p><strong>Use Case</strong>: Essential for researchers exploring multi-agent scenarios, such as swarm robotics, multiplayer games, or economic simulations.</p> <hr> <h2 id="10-stable-baselines3">10. Stable Baselines3</h2> <p><strong>What it is</strong>: Stable Baselines3 is a set of reliable implementations of RL algorithms in Python, built using PyTorch. It provides easy-to-use, pre-tested algorithms that can be readily applied to a variety of environments.</p> <p><strong>Key Features</strong>:</p> <ul> <li> <strong>Easy Integration</strong>: Compatible with OpenAI Gym environments.</li> <li> <strong>Wide Range of Algorithms</strong>: Offers stable implementations of popular RL algorithms like DQN, A2C, PPO, and SAC.</li> <li> <strong>Focus on Simplicity</strong>: Designed to be simple to use and modify, making it ideal for experimentation.</li> </ul> <p><strong>Use Case</strong>: A practical choice for practitioners who want to apply RL algorithms out-of-the-box or tweak existing implementations for research.</p> <hr> <p>Happy experimenting!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/kan/">Kolmogorov-Arnold Networks (KAN) (My Notes)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/rl/">Thoughts on RL challenges</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/kan_tmp/">Kan_tmp</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/mujoco/">Stuck at Installing Mujoco? Use this guide!!</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/robot/">Are Current Robotics Methods Deployable on Edge Robots?</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Hemant Kumawat. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-research",title:"Research",description:"A growing collection of my research projects.",section:"Navigation",handler:()=>{window.location.href="/research/"}},{id:"nav-cv",title:"CV",description:"Email me at hkumawat6@gatech.edu.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-kolmogorov-arnold-networks-kan-my-notes",title:"Kolmogorov-Arnold Networks (KAN) (My Notes)",description:"Review of Kolmogorov-Arnold Networks (KAN) and their mathematical foundation.",section:"Posts",handler:()=>{window.location.href="/blog/2024/kan/"}},{id:"post-thoughts-on-rl-challenges",title:"Thoughts on RL challenges",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/rl/"}},{id:"post-kan-tmp",title:"Kan_tmp",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2024/kan_tmp/"}},{id:"post-common-tools-in-reinforcement-learning-for-benchmarking",title:"Common Tools in Reinforcement Learning for Benchmarking",description:"A guide to the most popular tools used in reinforcement learning for benchmarking algorithms.",section:"Posts",handler:()=>{window.location.href="/blog/2024/benchmark/"}},{id:"post-stuck-at-installing-mujoco-use-this-guide",title:"Stuck at Installing Mujoco? Use this guide!!",description:"A step-by-step guide to installing Mujoco on your system.",section:"Posts",handler:()=>{window.location.href="/blog/2024/mujoco/"}},{id:"post-are-current-robotics-methods-deployable-on-edge-robots",title:"Are Current Robotics Methods Deployable on Edge Robots?",description:"A discussion on the challenges of deploying state-of-the-art robotics algorithms on edge robots.",section:"Posts",handler:()=>{window.location.href="/blog/2024/robot/"}},{id:"post-neural-ode-solvers-my-notes",title:"Neural ODE Solvers (My Notes)",description:"Some notes on ML for solving ordinary differential equations.",section:"Posts",handler:()=>{window.location.href="/blog/2022/ode/"}},{id:"news-i-am-reviewing-for-neurips-2024-iclr-2025-and-ijcnn-2024",title:"I am reviewing for Neurips 2024, ICLR 2025, and IJCNN 2024.",description:"",section:"News"},{id:"news-attending-l4dc-2024-in-oxford-uk-if-you-are-around-let-39-s-catch-up",title:"Attending L4DC 2024 in Oxford, UK. If you are around, let&#39;s catch up!...",description:"",section:"News"},{id:"news-our-work-on-learning-control-conditioned-representations-for-robotics-got-accepted-in-corl-2024",title:"Our work on learning control conditioned representations for robotics got accepted in **CORL...",description:"",section:"News"},{id:"projects-",title:"",description:"",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%68%6B%75%6D%61%77%61%74%36@%67%61%74%65%63%68.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=2iUnwBwAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/kumawathemant","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/kumawathemant","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/HeMan553","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>